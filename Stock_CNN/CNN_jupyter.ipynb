{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from statistics import mode\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Dropout, Activation, Flatten, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SET50 (unrealize)\n",
    "SET50 = ['ADVANC', 'AOT', 'BANPU', 'BBL', 'BCP', 'BDMS',\n",
    "        'BEAUTY', 'BEM', 'BH', 'BJC', 'BPP', 'BTS', 'CBG',\n",
    "        'CENTEL', 'CPALL', 'CPF', 'CPN', 'DTAC', 'EA', 'EGCO',\n",
    "        'GLOBAL', 'GPSC', 'HMPRO', 'INTUCH', 'IRPC', 'IVL', 'KBANK',\n",
    "        'KCE', 'KKP', 'KTB', 'LH', 'MINT', 'MTLS', 'PSH', 'PTT',\n",
    "        'PTTEP', 'PTTGC', 'ROBINS', 'SAWAD', 'SCB', 'SCC', 'SPRC',\n",
    "        'TCAP', 'TISCO', 'TMB', 'TOP', 'TPIPP', 'TRUE', 'TU', 'WHA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_stock_data(symbol, year_start, year_end):\n",
    "    stock_data = []\n",
    "    with open('./SET50/' + symbol + '.BK.csv', 'r') as csv_file:\n",
    "        file_data = csv.reader(csv_file, delimiter=',')\n",
    "        file_data = list(file_data)[1:]\n",
    "        temp_value = 0\n",
    "        for row in file_data:\n",
    "            if row[2] is '':\n",
    "                continue\n",
    "            elif int(row[0][0:4]) >= year_start and int(row[0][0:4]) <= year_end:\n",
    "                temp = (float(row[2]) + float(row[3]))/2.0\n",
    "                if temp_value != 0:\n",
    "                    unrealize = (temp - temp_value) / temp_value\n",
    "                else:\n",
    "                    unrealize = 0\n",
    "                unrealize = [\"{0:.3f}\".format(unrealize)]\n",
    "                stock_data.append(unrealize)\n",
    "                temp_value = temp\n",
    "                \n",
    "    return stock_data\n",
    "\n",
    "def findMean(x):\n",
    "    sums = 0.0\n",
    "    for i in x:\n",
    "        sums += float(i[0])\n",
    "        \n",
    "    returns = []\n",
    "    sums = \"{0:.3f}\".format(sums/len(x))\n",
    "    returns.append(sums)\n",
    "    return returns\n",
    "\n",
    "def mean_square_error(actual, expected):\n",
    "    length = len(actual)\n",
    "    sums_error = 0.0\n",
    "    for i, j in zip(actual, expected):\n",
    "        sums_error += (i[0] - j[0])**2\n",
    "    \n",
    "    return sums_error / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_datas = [ load_stock_data(x, 2007, 2017) for x in SET50 ]\n",
    "# delete date **\n",
    "e = mode([ len(x) for x in stock_datas])\n",
    "rounds = int(e / 22)\n",
    "delete_indexs = []\n",
    "for index, element in enumerate(stock_datas):\n",
    "    if len(element) < rounds * 22:\n",
    "        delete_indexs.append(index)\n",
    "        \n",
    "for i in reversed(delete_indexs):\n",
    "    del stock_datas[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "    \n",
    "model.add(Conv2D(64, (3, 3), input_shape=(len(stock_datas), 22, 1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3 ,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))   \n",
    "      \n",
    "model.add(Flatten())  \n",
    "model.add(Dense(512))  \n",
    "model.add(Activation('relu'))  \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))# equal symbols\n",
    "\n",
    "sgd = SGD(lr = 0.01, momentum = 0.9, decay= 1e-6, nesterov = True)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_index = int(rounds * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 1) (12, 1)\n"
     ]
    }
   ],
   "source": [
    "target = []\n",
    "index = 1\n",
    "while index < rounds:\n",
    "    temp = [stock_datas[i][index * 22] for i in range(len(stock_datas))]\n",
    "    target.append(findMean(temp))\n",
    "    index += 1\n",
    "    \n",
    "y = np.asarray(target)\n",
    "y_train = y[0: train_index].astype('float32')\n",
    "y_test = y[train_index: rounds].astype('float32')\n",
    "\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 29, 22, 1) (12, 29, 22, 1)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "count = 0\n",
    "index = 0\n",
    "while index < rounds - 1:\n",
    "    temp = [i[count : count + 22] for i in stock_datas]\n",
    "    data.append(temp)\n",
    "    count += 22\n",
    "    index += 1\n",
    "    \n",
    "x = np.asarray(data)\n",
    "x_train = x[0: train_index].astype('float32')\n",
    "x_test = x[train_index: rounds].astype('float32')\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 1.3799e-04 - val_loss: 5.9980e-06\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.3278e-04 - val_loss: 6.0441e-06\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.4684e-04 - val_loss: 7.3019e-06\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.8163e-04 - val_loss: 9.2517e-06\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 361us/step - loss: 2.3035e-04 - val_loss: 6.1425e-06\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.3655e-04 - val_loss: 5.8430e-06\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.4933e-04 - val_loss: 6.2400e-06\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 1.8078e-04 - val_loss: 6.9132e-06\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.4895e-04 - val_loss: 6.3254e-06\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.4620e-04 - val_loss: 5.6052e-06\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.3652e-04 - val_loss: 5.7596e-06\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.6856e-04 - val_loss: 5.9165e-06\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.4089e-04 - val_loss: 6.2375e-06\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.7968e-04 - val_loss: 6.3343e-06\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.4071e-04 - val_loss: 6.6326e-06\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 1.4067e-04 - val_loss: 7.1661e-06\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 380us/step - loss: 1.2006e-04 - val_loss: 7.9575e-06\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.3235e-04 - val_loss: 8.4376e-06\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.5008e-04 - val_loss: 8.1462e-06\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.2728e-04 - val_loss: 7.2132e-06\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.4192e-04 - val_loss: 7.0400e-06\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.1065e-04 - val_loss: 7.0305e-06\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.2479e-04 - val_loss: 7.2694e-06\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 1.2910e-04 - val_loss: 7.5585e-06\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.1788e-04 - val_loss: 7.5111e-06\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 0s 361us/step - loss: 1.0389e-04 - val_loss: 7.9344e-06\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 1.2862e-04 - val_loss: 7.7286e-06\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.3604e-04 - val_loss: 8.2181e-06\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.0839e-04 - val_loss: 7.9649e-06\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 1.4370e-04 - val_loss: 7.3706e-06\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.1357e-04 - val_loss: 7.2929e-06\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 1.2008e-04 - val_loss: 7.2011e-06\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.4109e-04 - val_loss: 7.2213e-06\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.2906e-04 - val_loss: 7.2140e-06\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.2837e-04 - val_loss: 7.3228e-06\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.1996e-04 - val_loss: 8.1237e-06\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 1.1727e-04 - val_loss: 1.0014e-05\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 9.4455e-05 - val_loss: 1.0590e-05\n",
      "Epoch 39/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.2332e-04 - val_loss: 1.0286e-05\n",
      "Epoch 40/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.1133e-04 - val_loss: 9.5357e-06\n",
      "Epoch 41/100\n",
      "108/108 [==============================] - 0s 371us/step - loss: 1.0750e-04 - val_loss: 8.3820e-06\n",
      "Epoch 42/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 9.6872e-05 - val_loss: 7.8089e-06\n",
      "Epoch 43/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.2133e-04 - val_loss: 7.9066e-06\n",
      "Epoch 44/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.0948e-04 - val_loss: 7.8135e-06\n",
      "Epoch 45/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.3112e-04 - val_loss: 8.1472e-06\n",
      "Epoch 46/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.1201e-04 - val_loss: 8.2700e-06\n",
      "Epoch 47/100\n",
      "108/108 [==============================] - 0s 361us/step - loss: 1.3781e-04 - val_loss: 8.4297e-06\n",
      "Epoch 48/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.1380e-04 - val_loss: 8.5696e-06\n",
      "Epoch 49/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.2047e-04 - val_loss: 9.0205e-06\n",
      "Epoch 50/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.2681e-04 - val_loss: 9.0629e-06\n",
      "Epoch 51/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.1686e-04 - val_loss: 8.5981e-06\n",
      "Epoch 52/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.2668e-04 - val_loss: 8.8441e-06\n",
      "Epoch 53/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.2261e-04 - val_loss: 9.2551e-06\n",
      "Epoch 54/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.1092e-04 - val_loss: 9.4497e-06\n",
      "Epoch 55/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.0915e-04 - val_loss: 9.8170e-06\n",
      "Epoch 56/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.1266e-04 - val_loss: 9.7430e-06\n",
      "Epoch 57/100\n",
      "108/108 [==============================] - 0s 361us/step - loss: 1.0298e-04 - val_loss: 9.6274e-06\n",
      "Epoch 58/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 9.4800e-05 - val_loss: 9.7656e-06\n",
      "Epoch 59/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.0266e-04 - val_loss: 9.1909e-06\n",
      "Epoch 60/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.0021e-04 - val_loss: 8.5979e-06\n",
      "Epoch 61/100\n",
      "108/108 [==============================] - 0s 361us/step - loss: 1.1808e-04 - val_loss: 8.4627e-06\n",
      "Epoch 62/100\n",
      "108/108 [==============================] - 0s 361us/step - loss: 1.0217e-04 - val_loss: 8.3604e-06\n",
      "Epoch 63/100\n",
      "108/108 [==============================] - 0s 361us/step - loss: 9.9545e-05 - val_loss: 8.7193e-06\n",
      "Epoch 64/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.2703e-04 - val_loss: 9.0024e-06\n",
      "Epoch 65/100\n",
      "108/108 [==============================] - 0s 361us/step - loss: 1.1900e-04 - val_loss: 9.0158e-06\n",
      "Epoch 66/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.1077e-04 - val_loss: 9.1218e-06\n",
      "Epoch 67/100\n",
      "108/108 [==============================] - 0s 361us/step - loss: 1.0746e-04 - val_loss: 9.2413e-06\n",
      "Epoch 68/100\n",
      "108/108 [==============================] - 0s 324us/step - loss: 9.6942e-05 - val_loss: 9.8954e-06\n",
      "Epoch 69/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.0381e-04 - val_loss: 1.0179e-05\n",
      "Epoch 70/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.1004e-04 - val_loss: 9.4812e-06\n",
      "Epoch 71/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 9.0351e-05 - val_loss: 8.9943e-06\n",
      "Epoch 72/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.0946e-04 - val_loss: 8.9313e-06\n",
      "Epoch 73/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.0243e-04 - val_loss: 9.6536e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.2709e-04 - val_loss: 1.0133e-05\n",
      "Epoch 75/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.0081e-04 - val_loss: 1.0177e-05\n",
      "Epoch 76/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 9.1962e-05 - val_loss: 9.8457e-06\n",
      "Epoch 77/100\n",
      "108/108 [==============================] - 0s 361us/step - loss: 1.2691e-04 - val_loss: 9.8619e-06\n",
      "Epoch 78/100\n",
      "108/108 [==============================] - 0s 333us/step - loss: 1.1174e-04 - val_loss: 8.9017e-06\n",
      "Epoch 79/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 9.7190e-05 - val_loss: 8.5353e-06\n",
      "Epoch 80/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 9.2476e-05 - val_loss: 8.1585e-06\n",
      "Epoch 81/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.0191e-04 - val_loss: 8.3746e-06\n",
      "Epoch 82/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.1421e-04 - val_loss: 8.2627e-06\n",
      "Epoch 83/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.1000e-04 - val_loss: 8.2528e-06\n",
      "Epoch 84/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 9.9106e-05 - val_loss: 8.3974e-06\n",
      "Epoch 85/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.1466e-04 - val_loss: 9.0685e-06\n",
      "Epoch 86/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.0520e-04 - val_loss: 1.0194e-05\n",
      "Epoch 87/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.0179e-04 - val_loss: 1.1111e-05\n",
      "Epoch 88/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 9.7920e-05 - val_loss: 1.0785e-05\n",
      "Epoch 89/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.2361e-04 - val_loss: 9.5563e-06\n",
      "Epoch 90/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.2723e-04 - val_loss: 8.5857e-06\n",
      "Epoch 91/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 9.6110e-05 - val_loss: 8.2743e-06\n",
      "Epoch 92/100\n",
      "108/108 [==============================] - 0s 380us/step - loss: 1.0108e-04 - val_loss: 8.2370e-06\n",
      "Epoch 93/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 9.2514e-05 - val_loss: 8.2777e-06\n",
      "Epoch 94/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.0347e-04 - val_loss: 8.2888e-06\n",
      "Epoch 95/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 1.0499e-04 - val_loss: 8.5256e-06\n",
      "Epoch 96/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.0574e-04 - val_loss: 8.8308e-06\n",
      "Epoch 97/100\n",
      "108/108 [==============================] - 0s 352us/step - loss: 1.1103e-04 - val_loss: 8.6719e-06\n",
      "Epoch 98/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 1.0455e-04 - val_loss: 8.5966e-06\n",
      "Epoch 99/100\n",
      "108/108 [==============================] - 0s 334us/step - loss: 9.6853e-05 - val_loss: 8.4924e-06\n",
      "Epoch 100/100\n",
      "108/108 [==============================] - 0s 343us/step - loss: 9.9253e-05 - val_loss: 8.5150e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d92b6cbdd8>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = epochs, shuffle = True, batch_size = 100, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.43944242e-03]\n",
      " [  1.56791846e-03]\n",
      " [  1.23050064e-04]\n",
      " [  1.06722268e-03]\n",
      " [  1.43525749e-03]\n",
      " [  1.35611917e-03]\n",
      " [  1.19774602e-03]\n",
      " [  8.66791059e-04]\n",
      " [  1.23048550e-03]\n",
      " [  6.91056601e-04]\n",
      " [ -6.86041312e-06]\n",
      " [  1.62228348e-03]]\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test, verbose = 0)\n",
    "\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.41176494518e-06\n"
     ]
    }
   ],
   "source": [
    "mse = mean_square_error(classes, y_test)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

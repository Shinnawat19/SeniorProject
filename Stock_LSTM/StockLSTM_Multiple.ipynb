{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "import os\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SET50 = ['ADVANC', 'AOT', 'BANPU', 'BBL', 'BCP', 'BDMS',\n",
    "        'BEM', 'BH', 'BJC', 'BTS', 'CENTEL', 'CPALL', \n",
    "         'CPF', 'CPN', 'DTAC', 'EGCO', 'GLOBAL', 'HMPRO', \n",
    "         'INTUCH', 'IRPC', 'KBANK', 'KCE', 'KKP', 'KTB', 'LH', 'MINT', 'PTT',\n",
    "        'PTTEP', 'ROBINS', 'SCB', 'SCC', \n",
    "        'TCAP', 'TISCO', 'TMB', 'TOP', 'TRUE', 'TU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_dataset(dataset, step_size):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset)-step_size-1):\n",
    "        a = dataset[i:(i+step_size), 0]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(dataset[i + step_size, 0])\n",
    "    return np.array(data_X), np.array(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path =r'C:\\Users\\asus\\Desktop\\Stock_LSTM\\SET50'\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "allName = os.listdir(path)\n",
    "d = {os.path.basename(f).split('.')[0]:pd.read_csv(f,usecols=[4]).dropna().reset_index(drop=True).round(1) for f in allFiles if \"\" in f}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train , test , data , target = [] , [] , [] , []\n",
    "for key, value in d.items():\n",
    "    d[key] = np.reshape(value.values, (len(value),1))\n",
    "    d[key] = scaler.fit_transform(value)\n",
    "    train.append(int(len(d[key])*0.8))\n",
    "    test.append(len(d[key]) - int(len(d[key])*0.8))\n",
    "    data.append(d[key][0:int(len(d[key])*0.8),:])\n",
    "    target.append(d[key][int(len(d[key])*0.8):len(d[key]),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , y_train , x_test , y_test = [] , [] , [] , []\n",
    "for value in data:\n",
    "    x_train.append(new_dataset(value,1))\n",
    "    y_train.append(new_dataset(value,1))\n",
    "for value in target:\n",
    "    x_test.append(new_dataset(value,1))\n",
    "    y_test.append(new_dataset(value,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, value in enumerate(x_train):\n",
    "    x_train[index] = np.reshape(x_train[index][0], (x_train[index][0].shape[0], 1, x_train[index][0].shape[1]))\n",
    "for index, value in enumerate(x_test):\n",
    "    x_test[index] = np.reshape(x_test[index][0], (x_test[index][0].shape[0], 1, x_test[index][0].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train\n",
      "(3362, 1, 1)\n",
      "(2503, 1, 1)\n",
      "(3536, 1, 1)\n",
      "(3386, 1, 1)\n",
      "(4324, 1, 1)\n",
      "(2623, 1, 1)\n",
      "(2146, 1, 1)\n",
      "(2504, 1, 1)\n",
      "(2662, 1, 1)\n",
      "(2320, 1, 1)\n",
      "(2638, 1, 1)\n",
      "(1253, 1, 1)\n",
      "(3342, 1, 1)\n",
      "(1613, 1, 1)\n",
      "(1852, 1, 1)\n",
      "(3391, 1, 1)\n",
      "(1577, 1, 1)\n",
      "(3143, 1, 1)\n",
      "(1325, 1, 1)\n",
      "(3006, 1, 1)\n",
      "(3394, 1, 1)\n",
      "(2407, 1, 1)\n",
      "(3284, 1, 1)\n",
      "(1677, 1, 1)\n",
      "(2554, 1, 1)\n",
      "(3145, 1, 1)\n",
      "(2972, 1, 1)\n",
      "(1566, 1, 1)\n",
      "(2334, 1, 1)\n",
      "(3392, 1, 1)\n",
      "(3311, 1, 1)\n",
      "(3342, 1, 1)\n",
      "(1569, 1, 1)\n",
      "(3387, 1, 1)\n",
      "(2374, 1, 1)\n",
      "(3536, 1, 1)\n",
      "(811, 1, 1)\n",
      "\n",
      "Shape of  x_test\n",
      "(840, 1, 1)\n",
      "(625, 1, 1)\n",
      "(883, 1, 1)\n",
      "(846, 1, 1)\n",
      "(1080, 1, 1)\n",
      "(655, 1, 1)\n",
      "(535, 1, 1)\n",
      "(625, 1, 1)\n",
      "(665, 1, 1)\n",
      "(579, 1, 1)\n",
      "(659, 1, 1)\n",
      "(312, 1, 1)\n",
      "(835, 1, 1)\n",
      "(402, 1, 1)\n",
      "(462, 1, 1)\n",
      "(847, 1, 1)\n",
      "(393, 1, 1)\n",
      "(785, 1, 1)\n",
      "(330, 1, 1)\n",
      "(750, 1, 1)\n",
      "(847, 1, 1)\n",
      "(601, 1, 1)\n",
      "(820, 1, 1)\n",
      "(418, 1, 1)\n",
      "(637, 1, 1)\n",
      "(785, 1, 1)\n",
      "(742, 1, 1)\n",
      "(390, 1, 1)\n",
      "(582, 1, 1)\n",
      "(847, 1, 1)\n",
      "(827, 1, 1)\n",
      "(835, 1, 1)\n",
      "(391, 1, 1)\n",
      "(846, 1, 1)\n",
      "(592, 1, 1)\n",
      "(883, 1, 1)\n",
      "(202, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of x_train')\n",
    "for index, value in enumerate(x_train):\n",
    "    print(x_train[index].shape)\n",
    "print('\\nShape of  x_test')\n",
    "for index, value in enumerate(x_test):\n",
    "    print(x_test[index].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 37 arrays: [array([[[ 0.05661713]],\n\n       [[ 0.04670913]],\n\n       [[ 0.03963199]],\n\n       ..., \n       [[ 0.87968861]],\n\n       [[ 0.89738146]],\n\n       [[ 0.90092003]]]), array([[[ 0.10973578]],\n\n       [[ ...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-282-2ddaf99fa5ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adagrad'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'mse'\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1581\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1582\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1412\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1414\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1415\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     86\u001b[0m                                  \u001b[1;34m'the following list of '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                                  \u001b[1;34m' arrays: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                                  '...')\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 37 arrays: [array([[[ 0.05661713]],\n\n       [[ 0.04670913]],\n\n       [[ 0.03963199]],\n\n       ..., \n       [[ 0.87968861]],\n\n       [[ 0.89738146]],\n\n       [[ 0.90092003]]]), array([[[ 0.10973578]],\n\n       [[ ..."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, step_size), return_sequences = True))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss='mse', optimizer='adagrad',metrics=['acc' , 'mse' ]) \n",
    "history = model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test) , batch_size=1, verbose=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

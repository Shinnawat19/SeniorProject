{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thetong\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SET50 = ['ADVANC', 'AOT', 'BANPU', 'BBL', 'BCP', 'BDMS',\n",
    "        'BEM', 'BH', 'BJC', 'BTS', 'CENTEL', 'CPALL', 'CPF',\n",
    "        'CPN', 'DTAC', 'EGCO', 'HMPRO', 'INTUCH', \n",
    "        'IRPC', 'KBANK', 'KCE', 'KKP', 'KTB', 'LH', 'MINT', \n",
    "        'PTT', 'PTTEP', 'ROBINS', 'SCB', 'SCC', \n",
    "        'TCAP', 'TISCO', 'TMB', 'TOP', 'TRUE', 'TU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_data(symbol, year_start, year_end):\n",
    "    stock_data = []\n",
    "    with open('./Data set/SET50_OHLC_FIXED/' + symbol + '.BK.csv', 'r') as csv_file:\n",
    "        file_data = csv.reader(csv_file, delimiter=',')\n",
    "        file_data = list(file_data)[1:]\n",
    "        ma = []\n",
    "        for row in file_data:\n",
    "            if row[1] is '':\n",
    "                continue\n",
    "            elif int(row[0][0:4]) == year_start - 1:\n",
    "                if len(ma) < 30:\n",
    "                    ma.append([float(row[1]), float(row[2]), float(row[3]), float(row[4])])\n",
    "                    continue\n",
    "                temp = [float(row[1]), float(row[2]), float(row[3]), float(row[4])]\n",
    "                stock_data.append(find_diff_ma(ma, temp))\n",
    "                del ma[0]\n",
    "                ma.append(temp)\n",
    "                if len(stock_data) > 29:\n",
    "                    del stock_data[0]\n",
    "            elif int(row[0][0:4]) >= year_start and int(row[0][0:4]) <= year_end:\n",
    "                temp = [float(row[1]), float(row[2]), float(row[3]), float(row[4])]\n",
    "                stock_data.append(find_diff_ma(ma, temp))\n",
    "                del ma[0]\n",
    "                ma.append(temp)\n",
    "    return stock_data\n",
    "\n",
    "def find_diff_ma(moving_averages, current_values):\n",
    "    returns = []\n",
    "    for i in range(len(moving_averages[0])):\n",
    "        data = [moving_average[i] for moving_average in moving_averages]\n",
    "        ma = np.sum(data) / 30\n",
    "        diff_ma = current_values[i] - ma\n",
    "        returns.append(diff_ma)\n",
    "    return returns\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_stock_data(symbol, year_start, year_end):\n",
    "    stock_data = []\n",
    "    with open('./Data set/SET50_OHLC_FIXED/' + symbol + '.BK.csv', 'r') as csv_file:\n",
    "        file_data = csv.reader(csv_file, delimiter=',')\n",
    "        file_data = list(file_data)[1:]\n",
    "        ma = []\n",
    "        for row in file_data:\n",
    "            if row[1] is '':\n",
    "                continue\n",
    "            elif len(ma) < 30:\n",
    "                ma.append([float(row[1]), float(row[2]), float(row[3]), float(row[4])])\n",
    "            elif int(row[0][0:4]) >= year_start and int(row[0][0:4]) <= year_end:\n",
    "                temp = [float(row[1]), float(row[2]), float(row[3]), float(row[4])]\n",
    "                stock_data.append(find_diff_ma(ma, temp))\n",
    "                del ma[0]\n",
    "                ma.append(temp)\n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [ load_stock_data(SET50[i], 2008, 2014) for i in range(len(SET50))]\n",
    "test = [ load_test_data(SET50[i], 2015, 2017) for i in range(len(SET50))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_length = len(train[0])\n",
    "test_length = len(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1685, 759)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_length, test_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 36, 30, 4) (237, 36, 120) (237, 1, 36, 30, 4)\n"
     ]
    }
   ],
   "source": [
    "data_train = []\n",
    "index = 0\n",
    "while index + 30 < train_length:\n",
    "    temp = [i[index : index + 30] for i in train]\n",
    "    data_train.append(temp)\n",
    "    index += 7\n",
    "    \n",
    "x_train = np.asarray(data_train).astype('float32')\n",
    "x_lstm_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2] * x_train.shape[3]))\n",
    "x_cnnlstm_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1], x_train.shape[2] , x_train.shape[3]))\n",
    "\n",
    "print(x_train.shape, x_lstm_train.shape, x_cnnlstm_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 36, 30, 4) (105, 36, 120) (105, 1, 36, 30, 4)\n"
     ]
    }
   ],
   "source": [
    "data_test = []\n",
    "index = 0\n",
    "while index + 30 < test_length:\n",
    "    temp = [i[index : index + 30] for i in test]\n",
    "    data_test.append(temp)\n",
    "    index += 7\n",
    "    \n",
    "x_test = np.asarray(data_test).astype('float32')\n",
    "x_lstm_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2] * x_test.shape[3]))\n",
    "x_cnnlstm_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1], x_test.shape[2] , x_test.shape[3]))\n",
    "\n",
    "print(x_test.shape, x_lstm_test.shape, x_cnnlstm_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_every_30_days(x, model):\n",
    "    predicts = []\n",
    "    for (index, element) in enumerate(x):\n",
    "        data = np.asarray([element])\n",
    "        for i in range(30):\n",
    "            predict = model.predict(data, verbose = 0)\n",
    "            predicts.append(np.asarray(predict[0]).T)\n",
    "            data = find_new_data(data, predict[0])\n",
    "    return predicts\n",
    "    \n",
    "def find_new_data(x, predict):\n",
    "    for (index, element) in enumerate(x[0]):\n",
    "        for i in range(len(element)):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            elif i < 29:\n",
    "                element[i - 1] = element[i]\n",
    "            else:\n",
    "                element[i - 1] = element[i]\n",
    "                element[i] = predict[index]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_model = load_model('./models/CNNMAinput4output1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_predictions = predict_every_30_days(x_train, cnn_model)\n",
    "cnn_predictions_test = predict_every_30_days(x_test, cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_predictions = np.asarray(cnn_predictions).T\n",
    "np.savetxt('cnn7Predictions.txt', cnn_predictions, fmt='%f')\n",
    "cnn_predictions_test = np.asarray(cnn_predictions_test).T\n",
    "np.savetxt('cnn7TestPredictions.txt', cnn_predictions_test, fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm_model = load_model('./models/LSTM_ma_4in1out.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions = predict_every_30_days(x_lstm_train, lstm_model)\n",
    "lstm_predictions_test = predict_every_30_days(x_lstm_test, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_predictions = np.asarray(lstm_predictions).T\n",
    "np.savetxt('lstm7Predictions.txt', lstm_predictions_test, fmt='%f')\n",
    "lstm_predictions_test = np.asarray(lstm_predictions_test).T\n",
    "np.savetxt('lstm7TestPredictions.txt', lstm_predictions_test, fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN LSTM PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnnlstm_model = load_model('./models/cnnlstmMA4Input1Output.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnnlstm_predictions = predict_every_30_days(x_cnnlstm_train, cnnlstm_model)\n",
    "cnnlstm_predictions_test = predict_every_30_days(x_cnnlstm_test, cnnlstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnnlstm_predictions = np.asarray(cnnlstm_predictions).T\n",
    "np.savetxt('cnnlstm7Predictions.txt', cnnlstm_predictions_test, fmt='%f')\n",
    "cnnlstm_predictions_test = np.asarray(cnnlstm_predictions_test).T\n",
    "np.savetxt('cnnlstm7TestPredictions.txt', cnnlstm_predictions_test, fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

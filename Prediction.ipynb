{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SET50 = ['ADVANC', 'AOT', 'BANPU', 'BBL', 'BCP', 'BDMS',\n",
    "        'BEM', 'BH', 'BJC', 'BTS', 'CENTEL', 'CPALL', 'CPF',\n",
    "        'CPN', 'DTAC', 'EGCO', 'HMPRO', 'INTUCH', \n",
    "        'IRPC', 'KBANK', 'KCE', 'KKP', 'KTB', 'LH', 'MINT', \n",
    "        'PTT', 'PTTEP', 'ROBINS', 'SCB', 'SCC', \n",
    "        'TCAP', 'TISCO', 'TMB', 'TOP', 'TRUE', 'TU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data method\n",
    "Look at prepare data\n",
    "** Change path before using **\n",
    "\n",
    "** load test data: first 30 days using from previous year **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_data(symbol, year_start, year_end):\n",
    "    stock_data = []\n",
    "    with open('./Data set/SET50_OHLC_FIXED/' + symbol + '.BK.csv', 'r') as csv_file:\n",
    "        file_data = csv.reader(csv_file, delimiter=',')\n",
    "        file_data = list(file_data)[1:]\n",
    "        ma = []\n",
    "        for row in file_data:\n",
    "            if row[1] is '':\n",
    "                continue\n",
    "            elif int(row[0][0:4]) == year_start - 1:\n",
    "                if len(ma) < 30:\n",
    "                    ma.append([float(row[1]), float(row[2]), float(row[3]), float(row[4])])\n",
    "                    continue\n",
    "                temp = [float(row[1]), float(row[2]), float(row[3]), float(row[4])]\n",
    "                stock_data.append(find_diff_ma(ma, temp))\n",
    "                del ma[0]\n",
    "                ma.append(temp)\n",
    "                if len(stock_data) > 29:\n",
    "                    del stock_data[0]\n",
    "            elif int(row[0][0:4]) >= year_start and int(row[0][0:4]) <= year_end:\n",
    "                temp = [float(row[1]), float(row[2]), float(row[3]), float(row[4])]\n",
    "                stock_data.append(find_diff_ma(ma, temp))\n",
    "                del ma[0]\n",
    "                ma.append(temp)\n",
    "    return stock_data\n",
    "\n",
    "def find_diff_ma(moving_averages, current_values):\n",
    "    returns = []\n",
    "    for i in range(len(moving_averages[0])):\n",
    "        data = [moving_average[i] for moving_average in moving_averages]\n",
    "        ma = np.sum(data) / 30\n",
    "        diff_ma = current_values[i] - ma\n",
    "        returns.append(diff_ma)\n",
    "    return returns\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_stock_data(symbol, year_start, year_end):\n",
    "    stock_data = []\n",
    "    with open('./Data set/SET50_OHLC_FIXED/' + symbol + '.BK.csv', 'r') as csv_file:\n",
    "        file_data = csv.reader(csv_file, delimiter=',')\n",
    "        file_data = list(file_data)[1:]\n",
    "        ma = []\n",
    "        for row in file_data:\n",
    "            if row[1] is '':\n",
    "                continue\n",
    "            elif len(ma) < 30:\n",
    "                ma.append([float(row[1]), float(row[2]), float(row[3]), float(row[4])])\n",
    "            elif int(row[0][0:4]) >= year_start and int(row[0][0:4]) <= year_end:\n",
    "                temp = [float(row[1]), float(row[2]), float(row[3]), float(row[4])]\n",
    "                stock_data.append(find_diff_ma(ma, temp))\n",
    "                del ma[0]\n",
    "                ma.append(temp)\n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = [ load_stock_data(SET50[i], 2008, 2014) for i in range(len(SET50))]\n",
    "test = [ load_test_data(SET50[i], 2015, 2017) for i in range(len(SET50))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_length = len(train[0])\n",
    "test_length = len(test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data shape\n",
    "CNN: (sets, stock count, stock data days, each stock per day) \n",
    "\n",
    "for example (1000, 36, 30, 1) = 1000 data sets, 36 stocks, 30 days, 1 data per day\n",
    "\n",
    "---\n",
    "LSTM: (sets, stock count, stock data)\n",
    "\n",
    "for example (1000, 36, 30) = 1000 data sets, 36 stocks, 30 data (1 data for 1 day)\n",
    "\n",
    "---\n",
    "CNNLSTM: (sets, time steps, stock count, stock data days, each stock per day)\n",
    "\n",
    "for example (1000, 1, 36, 30, 1) = 1000 data sets, 1 time steps, 36 stocks, 30 days, 1 data per day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "index = 0\n",
    "while index + 30 < train_length:\n",
    "    temp = [i[index : index + 30] for i in train]\n",
    "    data_train.append(temp)\n",
    "    index += 15\n",
    "    \n",
    "x_train = np.asarray(data_train).astype('float32')\n",
    "x_lstm_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2] * x_train.shape[3]))\n",
    "x_cnnlstm_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1], x_train.shape[2] , x_train.shape[3]))\n",
    "\n",
    "print(x_train.shape, x_lstm_train.shape, x_cnnlstm_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = []\n",
    "index = 0\n",
    "while index + 30 < test_length:\n",
    "    temp = [i[index : index + 30] for i in test]\n",
    "    data_test.append(temp)\n",
    "    index += 15\n",
    "    \n",
    "x_test = np.asarray(data_test).astype('float32')\n",
    "x_lstm_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2] * x_test.shape[3]))\n",
    "x_cnnlstm_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1], x_test.shape[2] , x_test.shape[3]))\n",
    "\n",
    "print(x_test.shape, x_lstm_test.shape, x_cnnlstm_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_every_30_days(x, model):\n",
    "    predicts = []\n",
    "    for (index, element) in enumerate(x):\n",
    "        data = np.asarray([element])\n",
    "        for i in range(30):\n",
    "            predict = model.predict(data, verbose = 0)\n",
    "            predicts.append(np.asarray(predict[0]).T)\n",
    "            data = find_new_data(data, predict[0])\n",
    "    return predicts\n",
    "    \n",
    "def find_new_data(x, predict):\n",
    "    for (index, element) in enumerate(x[0]):\n",
    "        for i in range(len(element)):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            elif i < 29:\n",
    "                element[i - 1] = element[i]\n",
    "            else:\n",
    "                element[i - 1] = element[i]\n",
    "                element[i] = predict[index]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_model = load_model('./models/CNNMAinput4output1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_predictions = predict_every_30_days(x_train, cnn_model)\n",
    "cnn_predictions_test = predict_every_30_days(x_test, cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_predictions = np.asarray(cnn_predictions).T\n",
    "np.savetxt('cnn15Predictions.txt', cnn_predictions, fmt='%f')\n",
    "cnn_predictions_test = np.asarray(cnn_predictions_test).T\n",
    "np.savetxt('cnn15TestPredictions.txt', cnn_predictions_test, fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm_model = load_model('./models/LSTM_ma_4in1out.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_predictions = predict_every_30_days(x_lstm_train, lstm_model)\n",
    "lstm_predictions_test = predict_every_30_days(x_lstm_test, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_predictions = np.asarray(lstm_predictions).T\n",
    "np.savetxt('lstm7Predictions.txt', lstm_predictions_test, fmt='%f')\n",
    "lstm_predictions_test = np.asarray(lstm_predictions_test).T\n",
    "np.savetxt('lstm7TestPredictions.txt', lstm_predictions_test, fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN LSTM PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnnlstm_model = load_model('./models/cnnlstmMA4Input1Output.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnnlstm_predictions = predict_every_30_days(x_cnnlstm_train, cnnlstm_model)\n",
    "cnnlstm_predictions_test = predict_every_30_days(x_cnnlstm_test, cnnlstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnnlstm_predictions = np.asarray(cnnlstm_predictions).T\n",
    "np.savetxt('cnnlstm7Predictions.txt', cnnlstm_predictions_test, fmt='%f')\n",
    "cnnlstm_predictions_test = np.asarray(cnnlstm_predictions_test).T\n",
    "np.savetxt('cnnlstm7TestPredictions.txt', cnnlstm_predictions_test, fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
